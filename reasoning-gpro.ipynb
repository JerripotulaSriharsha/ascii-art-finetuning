{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69101565",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\unsloth_env\\Lib\\site-packages\\unsloth_zoo\\gradient_checkpointing.py:341: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\c10/cuda/CUDAAllocatorConfig.h:35.)\n",
      "  GPU_BUFFERS = tuple([torch.empty(2*256*2048, dtype = dtype, device = f\"{DEVICE_TYPE}:{i}\") for i in range(n_gpus)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.9.9: Fast Qwen2 patching. Transformers: 4.56.2.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 4060 Laptop GPU. Num GPUs = 1. Max memory: 7.996 GB. Platform: Windows.\n",
      "O^O/ \\_/ \\    Torch: 2.8.0+cu126. CUDA: 8.9. CUDA Toolkit: 12.6. Triton: 3.4.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.32.post2. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.9.9 patched 36 layers with 36 QKV layers, 36 O layers and 36 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "max_seq_length = 1024\n",
    "lora_rank = 32\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"Qwen/Qwen2.5-3B-Instruct\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    load_in_4bit = True,\n",
    ")\n",
    "\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = lora_rank,\n",
    "    target_modules = [\n",
    "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "        \"gate_proj\", \"up_proj\", \"down_proj\",\n",
    "    ],\n",
    "    lora_alpha = lora_rank,\n",
    "    use_gradient_checkpointing = \"unsloth\",\n",
    "    random_state = 3407,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7c0ebc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\unsloth_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from datasets import load_dataset, Dataset\n",
    "\n",
    "# Load and prep dataset\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "Respond in the following format:\n",
    "<reasoning>\n",
    "...\n",
    "</reasoning>\n",
    "<answer>\n",
    "...\n",
    "</answer>\n",
    "\"\"\"\n",
    "\n",
    "XML_COT_FORMAT = \"\"\"\\\n",
    "<reasoning>\n",
    "{reasoning}\n",
    "</reasoning>\n",
    "<answer>\n",
    "{answer}\n",
    "</answer>\n",
    "\"\"\"\n",
    "\n",
    "def extract_xml_answer(text: str) -> str:\n",
    "    answer = text.split(\"<answer>\")[-1]\n",
    "    answer = answer.split(\"</answer>\")[0]\n",
    "    return answer.strip()\n",
    "\n",
    "def extract_hash_answer(text: str) -> str | None:\n",
    "    if \"####\" not in text:\n",
    "        return None\n",
    "    return text.split(\"####\")[1].strip()\n",
    "\n",
    "# uncomment middle messages for 1-shot prompting\n",
    "def get_gsm8k_questions(split = \"train\") -> Dataset:\n",
    "    data = load_dataset('openai/gsm8k', 'main')[split] # type: ignore\n",
    "    data = data.map(lambda x: { # type: ignore\n",
    "        'prompt': [\n",
    "            {'role': 'system', 'content': SYSTEM_PROMPT},\n",
    "            {'role': 'user', 'content': x['question']}\n",
    "        ],\n",
    "        'answer': extract_hash_answer(x['answer'])\n",
    "    }) # type: ignore\n",
    "    return data # type: ignore\n",
    "\n",
    "dataset = get_gsm8k_questions()\n",
    "\n",
    "# Reward functions\n",
    "def correctness_reward_func(prompts, completions, answer, **kwargs) -> list[float]:\n",
    "    responses = [completion[0]['content'] for completion in completions]\n",
    "    q = prompts[0][-1]['content']\n",
    "    extracted_responses = [extract_xml_answer(r) for r in responses]\n",
    "    print('-'*20, f\"Question:\\n{q}\", f\"\\nAnswer:\\n{answer[0]}\", f\"\\nResponse:\\n{responses[0]}\", f\"\\nExtracted:\\n{extracted_responses[0]}\")\n",
    "    return [2.0 if r == a else 0.0 for r, a in zip(extracted_responses, answer)]\n",
    "\n",
    "def int_reward_func(completions, **kwargs) -> list[float]:\n",
    "    responses = [completion[0]['content'] for completion in completions]\n",
    "    extracted_responses = [extract_xml_answer(r) for r in responses]\n",
    "    return [0.5 if r.isdigit() else 0.0 for r in extracted_responses]\n",
    "\n",
    "def strict_format_reward_func(completions, **kwargs) -> list[float]:\n",
    "    \"\"\"Reward function that checks if the completion has a specific format.\"\"\"\n",
    "    pattern = r\"^<reasoning>\\n.*?\\n</reasoning>\\n<answer>\\n.*?\\n</answer>\\n$\"\n",
    "    responses = [completion[0][\"content\"] for completion in completions]\n",
    "    matches = [re.match(pattern, r) for r in responses]\n",
    "    return [0.5 if match else 0.0 for match in matches]\n",
    "\n",
    "def soft_format_reward_func(completions, **kwargs) -> list[float]:\n",
    "    \"\"\"Reward function that checks if the completion has a specific format.\"\"\"\n",
    "    pattern = r\"<reasoning>.*?</reasoning>\\s*<answer>.*?</answer>\"\n",
    "    responses = [completion[0][\"content\"] for completion in completions]\n",
    "    matches = [re.match(pattern, r) for r in responses]\n",
    "    return [0.5 if match else 0.0 for match in matches]\n",
    "\n",
    "def count_xml(text) -> float:\n",
    "    count = 0.0\n",
    "    if text.count(\"<reasoning>\\n\") == 1:\n",
    "        count += 0.125\n",
    "    if text.count(\"\\n</reasoning>\\n\") == 1:\n",
    "        count += 0.125\n",
    "    if text.count(\"\\n<answer>\\n\") == 1:\n",
    "        count += 0.125\n",
    "        count -= len(text.split(\"\\n</answer>\\n\")[-1])*0.001\n",
    "    if text.count(\"\\n</answer>\") == 1:\n",
    "        count += 0.125\n",
    "        count -= (len(text.split(\"\\n</answer>\")[-1]) - 1)*0.001\n",
    "    return count\n",
    "\n",
    "def xmlcount_reward_func(completions, **kwargs) -> list[float]:\n",
    "    contents = [completion[0][\"content\"] for completion in completions]\n",
    "    return [count_xml(c) for c in contents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "467d7a55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?',\n",
       "       '72',\n",
       "       list([{'content': '\\nRespond in the following format:\\n<reasoning>\\n...\\n</reasoning>\\n<answer>\\n...\\n</answer>\\n', 'role': 'system'}, {'content': 'Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?', 'role': 'user'}])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dataset = pd.DataFrame(dataset)\n",
    "dataset.iloc[0,:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fc42302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: We now expect `per_device_train_batch_size` to be a multiple of `num_generations`.\n",
      "We will change the batch size of 1 to the `num_generations` of 6\n"
     ]
    }
   ],
   "source": [
    "max_prompt_length = 256\n",
    "\n",
    "from trl import GRPOConfig, GRPOTrainer\n",
    "training_args = GRPOConfig(\n",
    "    learning_rate = 5e-6,\n",
    "    adam_beta1 = 0.9,\n",
    "    adam_beta2 = 0.99,\n",
    "    weight_decay = 0.1,\n",
    "    warmup_ratio = 0.1,\n",
    "    lr_scheduler_type = \"cosine\",\n",
    "    optim = \"paged_adamw_8bit\",\n",
    "    logging_steps = 1,\n",
    "    per_device_train_batch_size = 1,\n",
    "    gradient_accumulation_steps = 1,\n",
    "    num_generations = 6,\n",
    "    max_prompt_length = max_prompt_length,\n",
    "    max_completion_length = max_seq_length - max_prompt_length,\n",
    "    # num_train_epochs = 1, # Set to 1 for a full training run\n",
    "    max_steps = 250,\n",
    "    save_steps = 250,\n",
    "    max_grad_norm = 0.1,\n",
    "    report_to = \"none\",\n",
    "    output_dir = \"outputs\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b0da45a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: We now expect `per_device_train_batch_size` to be a multiple of `num_generations`.\n",
      "We will change the batch size of 1 to the `num_generations` of 6\n"
     ]
    }
   ],
   "source": [
    "max_prompt_length = 256\n",
    "max_seq_length = 1024\n",
    "\n",
    "from trl import GRPOConfig, GRPOTrainer\n",
    "training_args = GRPOConfig(\n",
    "    learning_rate = 5e-6,\n",
    "    adam_beta1 = 0.9,\n",
    "    adam_beta2 = 0.99,\n",
    "    weight_decay = 0.1,\n",
    "    warmup_ratio = 0.1,\n",
    "    lr_scheduler_type = \"cosine\",\n",
    "    optim = \"paged_adamw_8bit\",\n",
    "    logging_steps = 1,\n",
    "    per_device_train_batch_size = 1,\n",
    "    gradient_accumulation_steps = 1,\n",
    "    num_generations = 6,\n",
    "    max_prompt_length = max_prompt_length,\n",
    "    max_completion_length = max_seq_length - max_prompt_length,\n",
    "    # num_train_epochs = 1, # Set to 1 for a full training run\n",
    "    max_steps = 250,\n",
    "    save_steps = 250,\n",
    "    max_grad_norm = 0.1,\n",
    "    report_to = \"none\",\n",
    "    output_dir = \"outputs\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1114f37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = GRPOTrainer(\n",
    "    model = model,\n",
    "    processing_class = tokenizer,\n",
    "    reward_funcs = [\n",
    "        xmlcount_reward_func,\n",
    "        soft_format_reward_func,\n",
    "        strict_format_reward_func,\n",
    "        int_reward_func,\n",
    "        correctness_reward_func,\n",
    "    ],\n",
    "    args = training_args,\n",
    "    train_dataset = dataset,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f07d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 250\n",
      "O^O/ \\_/ \\    Batch size per device = 6 | Gradient accumulation steps = 1\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (6 x 1 x 1) = 6\n",
      " \"-____-\"     Trainable parameters = 59,867,136 of 3,145,805,824 (1.90% trained)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Question:\n",
      "A concert ticket costs $40. Mr. Benson bought 12 tickets and received a 5% discount for every ticket bought that exceeds 10. How much did Mr. Benson pay in all? \n",
      "Answer:\n",
      "476 \n",
      "Response:\n",
      "<reasoning>\n",
      "To solve this problem, we need to calculate the total cost of the concert tickets while considering the discount offered for each ticket purchased beyond the 10th ticket. Mr. Benson buys 12 tickets, so the first 10 tickets are sold at full price, and the remaining 2 tickets get the discount. The discounted price of each of the last 2 tickets is 95% of the original price ($40). The total cost will be the sum of the cost of the first 10 tickets and the cost of the last 2 tickets with the discount.\n",
      "</reasoning>\n",
      "<answer>\n",
      "The cost of the first 10 tickets is:\n",
      "10 * $40 = $400.\n",
      "\n",
      "For the next 2 tickets, applies a 5% discount, so each ticket costs only 95% of $40 ($40 * 0.95). Thus, the cost for those 2 tickets is:\n",
      "2 * ($40 * 0.95) = 2 * $38 = $76.\n",
      "\n",
      "The total amount Mr. Benson paid is the sum of these two amounts:\n",
      "$400 + $76 = $476.\n",
      "\n",
      "Therefore, Mr. Benson paid $476 in all.\n",
      "</answer> \n",
      "Extracted:\n",
      "The cost of the first 10 tickets is:\n",
      "10 * $40 = $400.\n",
      "\n",
      "For the next 2 tickets, applies a 5% discount, so each ticket costs only 95% of $40 ($40 * 0.95). Thus, the cost for those 2 tickets is:\n",
      "2 * ($40 * 0.95) = 2 * $38 = $76.\n",
      "\n",
      "The total amount Mr. Benson paid is the sum of these two amounts:\n",
      "$400 + $76 = $476.\n",
      "\n",
      "Therefore, Mr. Benson paid $476 in all.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  6/250 04:03 < 4:07:46, 0.02 it/s, Epoch 0.00/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>reward</th>\n",
       "      <th>reward_std</th>\n",
       "      <th>completions / mean_length</th>\n",
       "      <th>completions / min_length</th>\n",
       "      <th>completions / max_length</th>\n",
       "      <th>completions / clipped_ratio</th>\n",
       "      <th>completions / mean_terminated_length</th>\n",
       "      <th>completions / min_terminated_length</th>\n",
       "      <th>completions / max_terminated_length</th>\n",
       "      <th>kl</th>\n",
       "      <th>rewards / xmlcount_reward_func / mean</th>\n",
       "      <th>rewards / xmlcount_reward_func / std</th>\n",
       "      <th>rewards / soft_format_reward_func / mean</th>\n",
       "      <th>rewards / soft_format_reward_func / std</th>\n",
       "      <th>rewards / strict_format_reward_func / mean</th>\n",
       "      <th>rewards / strict_format_reward_func / std</th>\n",
       "      <th>rewards / int_reward_func / mean</th>\n",
       "      <th>rewards / int_reward_func / std</th>\n",
       "      <th>rewards / correctness_reward_func / mean</th>\n",
       "      <th>rewards / correctness_reward_func / std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022500</td>\n",
       "      <td>1.130241</td>\n",
       "      <td>254.500000</td>\n",
       "      <td>229.000000</td>\n",
       "      <td>295.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>254.500000</td>\n",
       "      <td>229.000000</td>\n",
       "      <td>295.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.394167</td>\n",
       "      <td>0.132711</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.204124</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.816497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.370333</td>\n",
       "      <td>0.689005</td>\n",
       "      <td>513.500000</td>\n",
       "      <td>396.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>462.600006</td>\n",
       "      <td>396.000000</td>\n",
       "      <td>527.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.370333</td>\n",
       "      <td>0.689005</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.600333</td>\n",
       "      <td>0.258579</td>\n",
       "      <td>318.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>318.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>0.005426</td>\n",
       "      <td>-0.600333</td>\n",
       "      <td>0.258579</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.552333</td>\n",
       "      <td>0.248033</td>\n",
       "      <td>283.000000</td>\n",
       "      <td>189.000000</td>\n",
       "      <td>420.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>283.000000</td>\n",
       "      <td>189.000000</td>\n",
       "      <td>420.000000</td>\n",
       "      <td>0.002633</td>\n",
       "      <td>-0.552333</td>\n",
       "      <td>0.248033</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Will smartly offload gradients to save VRAM!\n",
      "-------------------- Question:\n",
      "Jane is trying to decide whether to buy a house or a trailer. A house costs $480,000 and a trailer costs $120,000. Each loan will be paid in monthly installments over 20 years. How much more is the monthly payment on the house compared to the trailer? \n",
      "Answer:\n",
      "1500 \n",
      "Response:\n",
      "<reasoning>\n",
      "To solve this problem, we need to calculate the monthly payment for both the house and the trailer and then find the difference between these payments.\n",
      "\n",
      "First, let's find the total number of months for the loan over 20 years. Since there are 12 months in a year:\n",
      "\\[ 20 \\text{ years} \\times 12 \\text{ months/year} = 240 \\text{ months} \\]\n",
      "\n",
      "Next, we calculate the monthly payment for the trailer. The loan amount is $120,000 and the loan is over 240 months:\n",
      "\\[ \\text{Monthly Payment for Trailer} = \\frac{\\$120,000}{240 \\text{ months}} \\]\n",
      "\n",
      "For the house, the loan amount is $480,000:\n",
      "\\[ \\text{Monthly Payment for House} = \\frac{\\$480,000}{240 \\text{ months}} \\]\n",
      "\n",
      "We need to compare these monthly payments to find the difference.\n",
      "</reasoning>\n",
      "<answer>\n",
      "First, we calculated the monthly payment for the trailer:\n",
      "\\[ \\text{Monthly Payment for Trailer} = \\frac{\\$120,000}{240} = \\$500 \\]\n",
      "\n",
      "Next, we calculated the monthly payment for the house:\n",
      "\\[ \\text{Monthly Payment for House} = \\frac{\\$480,000}{240} = \\$2,000 \\]\n",
      "\n",
      "To find how much more the monthly payment on the house is compared to the trailer, we subtract the trailer's monthly payment from the house's monthly payment:\n",
      "\\[ \\$2,000 - \\$500 = \\$1,500 \\]\n",
      "\n",
      "Therefore, the monthly payment on the house is $1,500 more compared to the trailer. \n",
      "</answer> \n",
      "Extracted:\n",
      "First, we calculated the monthly payment for the trailer:\n",
      "\\[ \\text{Monthly Payment for Trailer} = \\frac{\\$120,000}{240} = \\$500 \\]\n",
      "\n",
      "Next, we calculated the monthly payment for the house:\n",
      "\\[ \\text{Monthly Payment for House} = \\frac{\\$480,000}{240} = \\$2,000 \\]\n",
      "\n",
      "To find how much more the monthly payment on the house is compared to the trailer, we subtract the trailer's monthly payment from the house's monthly payment:\n",
      "\\[ \\$2,000 - \\$500 = \\$1,500 \\]\n",
      "\n",
      "Therefore, the monthly payment on the house is $1,500 more compared to the trailer.\n",
      "-------------------- Question:\n",
      "Janet pays $40/hour for 3 hours per week of clarinet lessons and $28/hour for 5 hours a week of piano lessons. How much more does she spend on piano lessons than clarinet lessons in a year? \n",
      "Answer:\n",
      "1040 \n",
      "Response:\n",
      "<reasoning>\n",
      "To determine how much more Janet spends on piano lessons compared to clarinet lessons in a year, we first need to calculate the weekly cost for each type of lesson. We can do this by multiplying the hourly rate by the number of hours for each type of lesson.\n",
      "\n",
      "For clarinet lessons, the cost per week is:\n",
      "\\[ 40\\, \\text{hours/hour} \\times 3\\, \\text{hours/week} = 120\\, \\text{dollars/week} \\]\n",
      "\n",
      "For piano lessons, the cost per week is:\n",
      "\\[ 28\\, \\text{dollars/hour} \\times 5\\, \\text{hours/week} = 140\\, \\text{dollars/week} \\]\n",
      "\n",
      "Next, we calculate the yearly cost for each type of lesson:\n",
      "- The yearly cost for clarinet lessons:\n",
      "\\[ 120\\, \\text{dollars/week} \\times 52\\, \\text{weeks/year} = 6240\\, \\text{dollars/year} \\]\n",
      "\n",
      "- The yearly cost for piano lessons:\n",
      "\\[ 140\\, \\text{dollars/week} \\times 52\\, \\text{weeks/year} = 7280\\, \\text{dollars/year} \\]\n",
      "\n",
      "Now we find the difference between the yearly costs of piano and clarinet lessons:\n",
      "\\[ 7280\\, \\text{dollars/year} - 6240\\, \\text{dollars/year} = 1040\\, \\text{dollars/year} \\]\n",
      "\n",
      "So, Janet spends $1040 more on piano lessons than clarinet lessons in a year.\n",
      "</reasoning>\n",
      "<answer>\n",
      "Janet spends $1040 more on piano lessons than clarinet lessons in a year.\n",
      "</answer> \n",
      "Extracted:\n",
      "Janet spends $1040 more on piano lessons than clarinet lessons in a year.\n",
      "-------------------- Question:\n",
      "Sabrina is collecting herbs to make a poultice for her grandmother. She needs twice as many basil leaves as sage leaves and 5 fewer sage leaves than verbena leaves. If she needs 12 basil leaves, how many leaves total does she need? \n",
      "Answer:\n",
      "29 \n",
      "Response:\n",
      "<reasoning>\n",
      "Based on the problem, if Sabrina has 12 basil leaves and needs twice as many basil leaves as sage leaves, we can calculate the number of sage leaves she needs. Let's denote the number of sage leaves as S. According Dickson's Law of Composite Numbers, which is not directly applicable but here we infer a simple operation: \n",
      "\n",
      "Basil leaves = 2 * Sage leaves\n",
      "\n",
      "Given Basil leaves are 12, we can set up the equation:\n",
      "\n",
      "12 = 2 * S \n",
      "S = 12 / 2\n",
      "S = 6 \n",
      "\n",
      "So, Sabrina needs 6 sage leaves. Next, she also needs 5 fewer sage leaves than verbena leaves (V):\n",
      "\n",
      "Sage leaves = Verbena leaves - 5\n",
      "\n",
      "Since we already know the number of sage leaves (6), we set up:\n",
      "\n",
      "6 = V - 5\n",
      "V = 6 + 5\n",
      "V = 11\n",
      "\n",
      "So, Sabrina needs 11 verbena leaves. Adding the total number of leaves she needs, we sum basil leaves, sage leaves, and verbena leaves: \n",
      "\n",
      "Total leaves = Basil leaves + Sage leaves + Verbena leaves \n",
      "Total leaves = 12 + 6 + 11\n",
      "Total leaves = 29\n",
      "</reasoning>\n",
      "<answer>\n",
      "Sabrina needs a total of 29 leaves. </answer> \n",
      "Extracted:\n",
      "Sabrina needs a total of 29 leaves.\n",
      "-------------------- Question:\n",
      "Over the past five years, on July 4th, the high temperature for Washington, DC has been: 90 degrees in 2020, 90 degrees in 2019, 90 degrees in 2018, 79 degrees in 2017 and 71 degrees in 2016. What is the average temperature for July 4th in Washington, DC over the past 5 years? \n",
      "Answer:\n",
      "84 \n",
      "Response:\n",
      "<reasoning>\n",
      "To calculate the average temperature for July 4th in Washington, DC over the past 5 years, we need to follow these steps:\n",
      "1. Add up all the temperatures for the given years.\n",
      "2. Divide the sum by the number of years (which is 5).\n",
      "\n",
      "The high temperatures for the past five years (2016 to 2020) in Washington, DC are 71 degrees, 79 degrees, 90 degrees, 90 degrees, and 90 degrees.\n",
      "\n",
      "First, add the given temperatures:\n",
      "\\[\n",
      "71 + 79 + 90 + 90 + 90 = 420\n",
      "\\]\n",
      "\n",
      "Next, divide the total sum by the number of years (5) to find the average:\n",
      "\\[\n",
      "\\frac{420}{5} = 84\n",
      "\\]\n",
      "\n",
      "So, the average temperature for July 4th over the past 5 years in Washington, DC is 84 degrees.\n",
      "</reasoning>\n",
      "<answer>\n",
      "84 degrees\n",
      "</answer> \n",
      "Extracted:\n",
      "84 degrees\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcaf5add",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d25f10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdc9c05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa05615",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unsloth_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
